{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time\n",
    "from elice_solver import Solver\n",
    "from data_loader import get_loader\n",
    "from torch.backends import cudnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_save_dir': 'stargan_celeba_128/models', 'd_lr': 0.0001, 'resume_iters': None, 'lambda_gp': 10, 'log_step': 10, 'num_iters': 200000, 'g_repeat_num': 6, 'num_iters_decay': 100000, 'g_conv_dim': 64, 'd_repeat_num': 6, 'selected_attrs': ['Black_Hair', 'Blond_Hair', 'Brown_Hair', 'Male', 'Young'], 'model_save_step': 10000, 'lr_update_step': 1000, 'sample_step': 1000, 'test_iters': 200000, 'beta2': 0.999, 'sample_dir': 'stargan/samples', 'celeba_image_dir': 'test_data/', 'mode': 'test', 'beta1': 0.5, 'dataset': 'CelebA', 'result_dir': 'test_data/result', 'd_conv_dim': 64, 'celeba_crop_size': 178, 'lambda_rec': 10, 'c2_dim': 8, 'c_dim': 5, 'attr_path': 'test_data/info.txt', 'batch_size': 16, 'num_workers': 1, 'log_dir': 'stargan/logs', 'lambda_cls': 1, 'image_size': 128, 'g_lr': 0.0001, 'n_critic': 5}\n"
     ]
    }
   ],
   "source": [
    "args = dict()\n",
    "args['c_dim'] = 5\n",
    "args['c2_dim'] = 8\n",
    "args['celeba_crop_size'] = 178\n",
    "args['image_size'] = 128\n",
    "args['g_conv_dim'] = 64\n",
    "args['d_conv_dim'] = 64\n",
    "args['g_repeat_num'] = 6\n",
    "args['d_repeat_num'] = 6\n",
    "args['lambda_cls'] = 1\n",
    "args['lambda_rec'] = 10\n",
    "args['lambda_gp'] = 10\n",
    "# Training configuration.\n",
    "args['dataset'] = 'CelebA'\n",
    "args['batch_size'] = 16\n",
    "args['num_iters'] = 200000\n",
    "args['num_iters_decay'] = 100000\n",
    "args['g_lr'] = 0.0001\n",
    "args['d_lr'] = 0.0001\n",
    "args['n_critic'] = 5\n",
    "args['beta1']=0.5\n",
    "args['beta2']=0.999\n",
    "args['resume_iters']=None\n",
    "args['selected_attrs']=['Black_Hair', 'Blond_Hair', 'Brown_Hair', 'Male', 'Young']\n",
    "# Test configuration.\n",
    "args['test_iters'] = 200000\n",
    "\n",
    "#Miscellaneous\n",
    "args['num_workers'] = 1\n",
    "args['mode'] = 'test'\n",
    "#Directories\n",
    "args['celeba_image_dir'] = 'test_data/'\n",
    "args['attr_path'] = 'test_data/info.txt'\n",
    "args['log_dir'] = 'stargan/logs'\n",
    "args['model_save_dir'] = 'stargan_celeba_128/models'\n",
    "args['sample_dir'] = 'stargan/samples'\n",
    "args['result_dir'] = 'test_data/result'\n",
    "# Step size.\n",
    "args['log_step'] = 10\n",
    "args['sample_step'] = 1000\n",
    "args['model_save_step'] = 10000\n",
    "args['lr_update_step'] = 1000\n",
    "config = args\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished preprocessing the CelebA dataset...\n"
     ]
    }
   ],
   "source": [
    "celeba_loader = get_loader(config['celeba_image_dir'], config['attr_path'], config['selected_attrs'],\n",
    "                           config['celeba_crop_size'], config['image_size'], config['batch_size'],\n",
    "                           'CelebA', config['mode'], config['num_workers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the trained models from step 200000...\n",
      "i : 0 attr_name: Black_Hair\n",
      "i : 1 attr_name: Blond_Hair\n",
      "i : 2 attr_name: Brown_Hair\n",
      "i : 3 attr_name: Male\n",
      "i : 4 attr_name: Young\n",
      "hair_color_indices:  [0, 1, 2]\n",
      "Saved real and fake images into test_data/result/1-1-images-black.jpg...\n",
      "Saved real and fake images into test_data/result/2-1-images-blond.jpg...\n",
      "Saved real and fake images into test_data/result/3-1-images-brown.jpg...\n",
      "Saved real and fake images into test_data/result/4-1-images-gender.jpg...\n",
      "Saved real and fake images into test_data/result/5-1-images-age.jpg...\n",
      "5.796247243881226\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "solver = Solver(celeba_loader, config)\n",
    "solver.test()\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "elice_project",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
